{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import argus\n",
    "from argus import load_model, Model\n",
    "\n",
    "from src.utils import rle_decode, rle_encode\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import watershed, label\n",
    "from scipy import ndimage\n",
    "\n",
    "from src.models.unet_flex import UNetFlexProb\n",
    "from src.losses import ShipLoss\n",
    "from src.metrics import ShipIOUT\n",
    "from src.utils import  filename_without_ext\n",
    "from src.transforms import ProbOutputTransform, ImageToTensor\n",
    "from src.dataset import ShipDataset\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../../data/models/linknet34_folds_007/fold_0/'\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = (768, 768)\n",
    "\n",
    "SEGM_THRESH = 0.5\n",
    "DT_THRESH = 0.001\n",
    "PROB_THRESH = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    plt.figure(dpi=200)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def show_img_tensor(tensor):\n",
    "    img = np.moveaxis(tensor.numpy(), 0, -1)[:,:,::-1]\n",
    "    show_img(img)\n",
    "\n",
    "\n",
    "def show_in_cols(masks_list, n_col=3):\n",
    "    n_masks = len(masks_list)\n",
    "    n_row = n_masks//n_col\n",
    "    if n_masks % n_col > 0:\n",
    "        n_row += 1\n",
    "    \n",
    "    f, ax = plt.subplots(n_row, n_col, figsize=(18,6))\n",
    "    for i in range(n_masks):\n",
    "        a = ax[i//n_col][i%n_col]\n",
    "        a.imshow(masks_list[i])\n",
    "        a.axis('off')\n",
    "\n",
    "\n",
    "def show_trg_tensor(tensor):\n",
    "    masks = tensor.numpy()\n",
    "    masks_list = [masks[i, :, :] for i in range(masks.shape[0])]\n",
    "    show_in_cols(masks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShipMetaModel(Model):\n",
    "    nn_module = {\n",
    "        'UNetFlexProb': UNetFlexProb,\n",
    "    }\n",
    "    loss = {\n",
    "        'ShipLoss': ShipLoss\n",
    "    }\n",
    "    prediction_transform = {\n",
    "        'ProbOutputTransform': ProbOutputTransform\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_path(dir_path):\n",
    "    model_scores = []\n",
    "    for model_name in os.listdir(dir_path):\n",
    "        score = re.search(r'-(\\d+(?:\\.\\d+)?).pth', model_name)\n",
    "        if score is not None:\n",
    "            score = score.group(0)[1:-4]\n",
    "            model_scores.append((model_name, score))\n",
    "    model_score = sorted(model_scores, key=lambda x: x[1])\n",
    "    best_model_name = model_score[-1][0]\n",
    "    best_model_path = os.path.join(dir_path, best_model_name)\n",
    "    return best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(get_best_model_path(save_path))\n",
    "model = load_model('/workdir/data/model-049-0.864456.pth')\n",
    "model.nn_module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../data/datasets/ships_small/test_small/'\n",
    "test_ids = [filename_without_ext(file) for file in os.listdir(test_dir)]\n",
    "print(\"Images for testing:\", len(test_ids))\n",
    "deploy_dataset = ShipDataset(test_ids, imgs_dir=test_dir, masks=False, image_transform=ImageToTensor())\n",
    "deploy_loader = DataLoader(deploy_dataset, batch_size=BATCH_SIZE,\n",
    "                           shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_min = 8\n",
    "ellipticity_min = 5\n",
    "eps = 1e-9\n",
    "ell_f = 3\n",
    "area_diff_thres = 100\n",
    "def bin2uint(img):\n",
    "    return np.uint8(img*255)\n",
    "\n",
    "# https://stackoverflow.com/questions/42798659/how-to-remove-small-connected-objects-using-opencv\n",
    "def clean_small(mask, thres=10):\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(bin2uint(mask), connectivity=4)\n",
    "    sizes = stats[1:, -1];\n",
    "    nb_components = nb_components - 1\n",
    "    img2 = np.zeros((output.shape), dtype=np.bool)\n",
    "\n",
    "    for i in range(nb_components):\n",
    "        if sizes[i] >= thres:\n",
    "            img2[output == i + 1] = True\n",
    "    return img2\n",
    "\n",
    "def max_area(mask):\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(bin2uint(mask), connectivity=4)\n",
    "    sizes = stats[1:, -1];\n",
    "    return np.max(sizes)\n",
    "\n",
    "def fit_rect(mask):\n",
    "    j = 0\n",
    "    all_masks = np.zeros_like(mask)\n",
    "    for k in np.unique(mask)[1:]:\n",
    "        _, contours, hierarchy = cv2.findContours(bin2uint(mask==k), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        for i in range(len(contours)):\n",
    "            if hierarchy[0,i,3] == -1:\n",
    "                epsilon = 0.1*cv2.arcLength(contours[i],True)\n",
    "                approx = cv2.approxPolyDP(contours[i],epsilon,True)\n",
    "                rect = cv2.minAreaRect(approx)\n",
    "                if rect[1][0]<rect[1][1]:\n",
    "                    hw = (rect[1][0]*F_H, rect[1][1]*F_W)\n",
    "                else:\n",
    "                    hw = (rect[1][0]*F_W, rect[1][1]*F_H)\n",
    "                rect = (rect[0], hw, rect[2])\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "                filled_rectangle = cv2.fillPoly(np.zeros_like(mask), pts =[box], color=(1,1,1))\n",
    "                all_masks[filled_rectangle > 0] = j+1\n",
    "                j+=1\n",
    "\n",
    "    return all_masks\n",
    "\n",
    "def fill_con(markers):\n",
    "    ret = np.zeros_like(markers)\n",
    "    for i in np.unique(markers)[1:]:\n",
    "        img = np.zeros((markers.shape), dtype=np.bool)\n",
    "        img[markers == i] = True\n",
    "        _, contours, hierarchy = cv2.findContours(bin2uint(img),\n",
    "                                cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        img2 = np.zeros((markers.shape), dtype=np.uint8)\n",
    "        for cnt in contours:\n",
    "            hull = cv2.convexHull(cnt)\n",
    "            img2 = cv2.fillConvexPoly(img2.copy(), hull, (255,255,255), 8)\n",
    "        ret[img2>0] = i\n",
    "    return ret\n",
    "\n",
    "def dist_eq(mask):\n",
    "    distance = np.zeros_like(mask, dtype=np.float32)\n",
    "    _, markers = cv2.connectedComponents(mask)\n",
    "    for i in np.unique(markers)[1:]:\n",
    "        img = np.zeros((markers.shape), dtype=np.bool)\n",
    "        img[markers == i] = True\n",
    "        _, contours, hierarchy = cv2.findContours(bin2uint(img),\n",
    "                                cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        img2 = np.zeros((markers.shape), dtype=np.uint8)\n",
    "        for cnt in contours:\n",
    "            hull = cv2.convexHull(cnt)\n",
    "            img2 = cv2.fillConvexPoly(img2.copy(), hull, (255,255,255), 8)\n",
    "        dt = cv2.distanceTransform(img2, distanceType=cv2.DIST_L2, maskSize=5)\n",
    "        cv2.normalize(dt, dt, 0, 1.0, cv2.NORM_MINMAX)\n",
    "        distance += dt\n",
    "    return distance\n",
    "\n",
    "kernel_shape = (3, 3)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_shape)\n",
    "\n",
    "def waters(mask, base, dt, boundaries):\n",
    "    mask = clean_small(mask)\n",
    "    mask_uint8 = bin2uint(mask)\n",
    "    # Remove small FP objects on image edges\n",
    "    labeled_array, num_features = ndimage.label(mask_uint8)\n",
    "    objs = ndimage.find_objects(labeled_array)\n",
    "    for obj in objs:\n",
    "        for x, s in zip(obj, mask.shape):\n",
    "            d = abs(x.stop - x.start)\n",
    "            if (x.stop == s or x.start == 0) and d <= edge_min:\n",
    "                mask[obj] = False\n",
    "    mask_uint8 = bin2uint(mask)\n",
    "\n",
    "    # Boundaries separation\n",
    "    boundaries = clean_small(boundaries, 8)\n",
    "    _, contours, hierarchy = cv2.findContours(bin2uint(boundaries),\n",
    "                                              cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        if len(cnt) >4:\n",
    "            ellipse = cv2.fitEllipse(cnt)\n",
    "            if ellipse[1][0]/(ellipse[1][1]+eps) > ellipticity_min or ellipse[1][1]/(ellipse[1][0]+eps) > ellipticity_min:\n",
    "                if ellipse[1][0] > ellipse[1][1]:\n",
    "                    hw = (ellipse[1][0]*ell_f, 1)\n",
    "                else:\n",
    "                    hw = (1, ellipse[1][1]*ell_f)\n",
    "                ellipse = (ellipse[0], hw, ellipse[2])\n",
    "                box = cv2.boxPoints(ellipse)\n",
    "                box = np.int0(box)\n",
    "                mask_uint8 = cv2.drawContours(mask_uint8.copy(), [box] ,0, (0,0,0), 1)\n",
    "    \n",
    "    \n",
    "    #show_img(mask)\n",
    "    \n",
    "    \n",
    "    mask_uint8 = cv2.erode(mask_uint8, kernel, iterations=1)\n",
    "    bin_mask = mask_uint8 > 0\n",
    "    if np.count_nonzero(bin_mask) > 0:\n",
    "        mask_uint8 = bin2uint(clean_small(bin_mask, max(max_area(bin_mask)/area_diff_thres, 10)))\n",
    "\n",
    "        #show_img(mask_uint8)\n",
    "        D = dist_eq(mask_uint8)\n",
    "        #show_img(D)\n",
    "        _, localMax = cv2.threshold(D, 0.7*D.max(), 255, 0)\n",
    "        localMax = cv2.dilate(localMax, kernel, iterations=2)\n",
    "\n",
    "        #show_img(localMax)\n",
    "        markers = ndimage.label(localMax, structure=np.ones((3, 3)))[0]\n",
    "        labels = watershed(-D, markers, mask=bin2uint(base))\n",
    "        #show_img(labels)\n",
    "        #labels = fill_con(labels)\n",
    "        return np.uint8(labels)\n",
    "    else:\n",
    "        return np.zeros_like(mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGM_THRESH = 0.95\n",
    "SEGM_BASE_THRESH = 0.75\n",
    "DT_THRESH = 0.001\n",
    "PROB_THRESH = 0.001\n",
    "\n",
    "def postprocess(pred, p):\n",
    "    ret = None\n",
    "    if p > PROB_THRESH:\n",
    "        dt = (1 + pred[3,:,:] - pred[4, :, :])/2\n",
    "        dt = np.clip(dt, 0, 1.0)\n",
    "        mask = pred[0, :, :] > SEGM_THRESH\n",
    "        boundaries = pred[1, :, :] > 0.5\n",
    "        background = pred[2, :, :] > SEGM_THRESH\n",
    "        #show_img(boundaries)\n",
    "        #gauss = pred[5, :, :] > 0.1\n",
    "        mask = np.logical_and(mask, np.logical_not(boundaries))  # Mask-boundaries\n",
    "        #mask = np.logical_or(mask, gauss)  # Mask+gauss - finds small\n",
    "        base = pred[0, :, :] > SEGM_BASE_THRESH\n",
    "        #base = np.logical_and(base, np.logical_not(boundaries))  # Mask-boundaries\n",
    "        #base = np.logical_or(base, gauss)\n",
    "        if np.sum(base)>0:\n",
    "            ret = waters(mask, base, dt, boundaries)\n",
    "    else:\n",
    "        pass\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In case you want to make a mean prediction uncomment following lines:\n",
    "\n",
    "# save_paths = ['../../data/models/linknet34_folds_008/fold_0/']\n",
    "# models = [load_model(get_best_model_path(path)) for path in save_paths]\n",
    "\n",
    "# def predict_mean(inp):\n",
    "#     preds = [model.nn_module(inp) for model in models]\n",
    "#     imgs = torch.mean(torch.stack([p[0] for p in preds]), dim=0)\n",
    "#     probs = torch.mean(torch.stack([p[1] for p in preds]), dim=0)\n",
    "#     return [imgs, probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "F_W = 0.95\n",
    "F_H = 0.85\n",
    "def draw_on_image(img, mask):\n",
    "    for i in np.unique(mask)[1:]:\n",
    "        _, contours, hierarchy = cv2.findContours(bin2uint(mask==i),\n",
    "                                                  cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        for cnt in contours:\n",
    "            rect = cv2.minAreaRect(cnt)\n",
    "            if rect[1][0]<rect[1][1]:\n",
    "                hw = (rect[1][0], rect[1][1])\n",
    "            else:\n",
    "                hw = (rect[1][0], rect[1][1])\n",
    "            rect = (rect[0], hw, rect[2])\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            img = cv2.drawContours(img.copy(), [box] ,0, (255,0,0), 1, cv2.LINE_AA)\n",
    "    return img\n",
    "        \n",
    "\n",
    "s = 3\n",
    "for n, img in enumerate(deploy_loader):\n",
    "    print(n)\n",
    "    if n < s:\n",
    "        n+=1\n",
    "#         continue\n",
    "    with torch.no_grad():\n",
    "        pred = model.nn_module(img.cuda())#predict_mean(img.cuda())#\n",
    "        print(pred[0].shape)\n",
    "        print(pred[1].shape)\n",
    "        for i in range(pred[0].shape[0]):\n",
    "            img_i = img[i, ...]\n",
    "            pred_i = pred[0][i, ...].data.cpu()\n",
    "            pred_i_p = round(pred[1][i].data.cpu().item(), 5)\n",
    "            print(\"Prediction\", pred_i_p)\n",
    "            show_img_tensor(img_i)\n",
    "                #show_trg_tensor(pred_i)\n",
    "            ret = postprocess(pred_i.numpy(), pred_i_p)\n",
    "            if ret is not None:\n",
    "                #show_img(ret)\n",
    "#                 im = (np.moveaxis(img_i.numpy(), 0, -1)*255).astype(np.uint8)\n",
    "                im = (np.moveaxis(img_i.numpy(), 0, -1)[:,:,::-1]*255).astype(np.uint8)\n",
    "                ret_im = np.stack([np.uint8(ret/np.max(ret)*255),\n",
    "                                   np.zeros((768, 768), dtype=np.uint8),\n",
    "                                   np.zeros((768, 768), dtype=np.uint8)], axis=2)\n",
    "                dst = cv2.addWeighted(im, 1.0, ret_im, 0.5, 0)\n",
    "                show_img(dst)\n",
    "                show_img(draw_on_image(dst, ret))\n",
    "            #show_trg_tensor(pred_i)\n",
    "    break\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_rle_encode(img):\n",
    "    labels = label(img)\n",
    "    return multi_rle_encode_labled(labels)\n",
    "\n",
    "def multi_rle_encode_labled(labels):\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be done in case you made a list of images without ships (visually for example)\n",
    "stop_list = []\n",
    "with open(\"../../data/double_corrected_empty.txt\", \"r\") as f: \n",
    "    for line in f: \n",
    "        stop_list.append(line[:-1])\n",
    "print(len(stop_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../../data/test/'\n",
    "test_names = os.listdir(test_dir)\n",
    "for img in test_names:\n",
    "    print(img in stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['ImageId','EncodedPixels'])\n",
    "test_names = os.listdir(test_dir)\n",
    "\n",
    "transform = ImageToTensor()\n",
    "n = 0\n",
    "for img in tqdm.tqdm(test_names):\n",
    "    if img in stop_list:\n",
    "        df = df.append({'ImageId':img, 'EncodedPixels':np.NaN}, ignore_index=True)\n",
    "    else:\n",
    "        img_path = os.path.join(test_dir, img)\n",
    "        img_tensor = transform(cv2.imread(img_path)).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            pred = predict_mean(img_tensor.cuda())\n",
    "\n",
    "        for i in range(pred[0].shape[0]):\n",
    "            pred_i = pred[0][i, ...].data.cpu()\n",
    "            pred_i_p = round(pred[1][i].data.cpu().item(), 5)\n",
    "            ret = postprocess(pred_i.numpy(), pred_i_p)\n",
    "            rles = []\n",
    "            if ret is not None:\n",
    "                rles = multi_rle_encode_labled(ret)\n",
    "            if len(rles)>0:\n",
    "                for rle in rles:\n",
    "                    df = df.append({'ImageId':img, 'EncodedPixels':rle}, ignore_index=True)\n",
    "                #img_i = (np.moveaxis(img_tensor[i, ...].numpy(), 0, -1)*255).astype(np.uint8)\n",
    "                #cv2.imwrite(os.path.join('../../data/vis/subm6/', img), draw_on_image(img_i, ret)[:,:,::-1])\n",
    "            else:\n",
    "                df = df.append({'ImageId':img, 'EncodedPixels':np.NaN}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/submissions/submission9.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.ImageId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
